{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Preventing Undesirable Outputs with the Self-Critique Chain\n",
    "\n",
    "• Find the  [Notebook](https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2007%20-%20Guarding_Against_Undesirable_Outputs_with_the_Self_Critique_Chain.ipynb)  for this section at  [towardsai.net/book](http://towardsai.net/book).\n",
    "\n",
    "In a production setting, it is crucial to implement a system that ensures the responses generated by large language models (LLMs) are appropriate, avoiding outputs that may be harmful or misleading. Fortunately, these advanced models can self-correct, provided they are prompted correctly.\n",
    "\n",
    "The LangChain self-critique chain acts as a regulatory mechanism, reviewing the model’s output to ascertain whether it meets set expectations. In cases of non-compliance, the model is prompted to adjust its responses according to the application’s specific requirements. For instance, in a student mentoring context, this system ensures that the model promotes ethical behavior, like encouraging hard work over unethical shortcuts to achieve high academic performance.\n",
    "\n",
    "To illustrate how the self-critique chain works, let’s begin with an example of a response we aim to avoid. We use the ***GPT-3.5 model (gpt-3.5-turbo)*** and create a prompt for an assistant who advises students based on their goals. The `LLMChain` class is then utilized to link the model and the prompt, enabling the retrieval of the model’s response through the `.run()` method.\n",
    "\n",
    ">Before executing the upcoming code, ensure your OpenAI key is set in the OPENAI_API_KEY environment variable and install the necessary packages using this command: !pip install langchain==0.0.208 deeplake openai==0.27.8 tiktoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_custom_utils.helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-building-llm-powered-applications-with-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
