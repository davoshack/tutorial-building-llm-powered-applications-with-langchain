{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Prompts and Example Selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Find the  [Notebook](https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2006%20-%20Getting_the_Best_of_Few_Shot_Prompts_and_Example_Selectors.ipynb)  for this section at  [towardsai.net/book](http://towardsai.net/book).\n",
    "\n",
    "We’ll cover how few-shot prompts and example selectors can enhance the performance of language models in LangChain. While various methods can be used to implement  **few-shot prompting**  and  **example selectors**  in LangChain, we’ll discuss three distinct approaches, examining their advantages and disadvantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_custom_utils.helper import get_openai_api_key, get_deeplake_api_key, print_response\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "DEEPLAKE_API_KEY = get_deeplake_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Human/AI Messages\n",
    "\n",
    "Using few-shot prompting with alternating human and AI messages is particularly useful for chat-based applications. This technique requires the language model to understand the conversational context and respond appropriately.\n",
    "\n",
    "Although this strategy is effective in managing conversational contexts and straightforward to implement, its flexibility is limited to chat-based applications. Despite this, alternating human/AI messages can be creatively employed. In this approach, you are essentially writing the chatbot’s responses in your own words and using them as input for the model.\n",
    "\n",
    "For example, we can create a chat prompt that translates English into pirate language by showing an example to the model using `AIMessagePromptTemplate`. Below is a code snippet illustrating it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "template=\"You are a helpful assistant that translates english to pirate.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "example_human = HumanMessagePromptTemplate.from_template(\"Hi\")\n",
    "example_ai = AIMessagePromptTemplate.from_template(\"Argh me mateys\")\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, example_human, example_ai, human_message_prompt])\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "chain.run(\"I love programming.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-building-llm-powered-applications-with-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
