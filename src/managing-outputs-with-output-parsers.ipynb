{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Outputs with Output Parsers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a production setting, outputs from language models in a predictable data structure are often desirable. Consider, for instance, developing a thesaurus application to generate a collection of alternative words relevant to the given context. Large language models (LLMs) can generate numerous suggestions for synonyms or similar terms. Below is an example of output from ChatGPT listing several words closely related to â€œbehavior.â€\n",
    "\n",
    "    Here are some substitute words for \"behavior\":  \n",
    "      \n",
    "    Conduct  \n",
    "    Manner  \n",
    "    Demeanor  \n",
    "    Attitude  \n",
    "    Disposition  \n",
    "    Deportment  \n",
    "    Etiquette  \n",
    "    Protocol  \n",
    "    Performance  \n",
    "    Actions\n",
    "\n",
    "The challenge arises from the absence of a dynamic method to extract relevant information from the provided text. Consider splitting the response by new lines and disregarding the initial lines. However, this approach is unreliable as thereâ€™s no assurance that responses will maintain a consistent format. The list might be numbered, or it might not include an introductory line.\n",
    "\n",
    "Output Parsers enable us to define a data structure that precisely describes what is expected from the model. In a word suggestion application, you might request a list of words or a combination of different variables, such as a word and an explanation.\n",
    "\n",
    "Structured outputs can also be enforced through APIs, such as those provided by OpenAI models, where the model can be prompted to generate outputs following a predefined schema. For instance, you can specify a JSON schema or use a Pydantic model to ensure that the outputs conform to the expected structure, making it easier to integrate into applications that require predictable data formats. This capability will be covered in more detail in the book, where we will explore practical methods to structure and validate outputs using these techniques.\n",
    "\n",
    "The Pydantic parser is versatile and has three unique types. However, other options are also available for less complex tasks.\n",
    "\n",
    "**Note:**  The thesaurus application will serve as a practical example to clarify the nuances of each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PydanticOutputParser\n",
    "\n",
    "This class instructs the model to produce its output in JSON format. The parserâ€™s output can be treated as a list, allowing for simple indexing of the results and eliminating formatting issues.\n",
    "\n",
    "```\n",
    "ðŸ’¡It is important to note that not all models have the same capability to generate JSON outputs. So, it would be best to use a more powerful model (like Anthropic or OpenAIâ€™s most recent models) to get the best result.\n",
    "```\n",
    "This wrapper uses the Pydantic library to define and validate data structures in Python. It allows determining the expected output structure, including its name, type, and description. For instance, a variable must hold multiple suggestions, like a list, in the thesaurus application. This is achieved by creating a class that inherits the Pydanticâ€™s `BaseModel class`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Set the OPENAI_API_KEY environment variable with your API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_custom_utils.helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-3.5-turbo'\n",
    "temperature = 0.0\n",
    "model = ChatOpenAI(model_name=model_name, temperature=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic OutputParser Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "\n",
    "    # Throw error in case of recieving a numbered-list from API\n",
    "    @validator('words')\n",
    "    def not_start_with_number(cls, field):\n",
    "        if field[0].isnumeric():\n",
    "            raise ValueError(\"The word can not start with numbers!\")\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and create the `Suggestions` schema class, which consists of two components:\n",
    "\n",
    "1.  **Expected Outputs:** Each output is defined by declaring a variable with the desired type, such as a list of strings (: List[str]) in the example code. Alternatively, it could be a single string (: str) for cases expecting a singular word or sentence as the response. Itâ€™s mandatory to provide a brief description using the Field functionâ€™s description attribute, aiding the model during inference. (An illustration of handling multiple outputs will be presented later in the book.)\n",
    "2.  **Validators:** We can declare functions to validate the formatting. For instance, the provided code has a validation to ensure the first character is not a number. The functionâ€™s name is not critical, but the @validator decorator must be applied to the variable requiring validation (e.g., @validator('words')). Note that if the variable is specified as a list, the field argument within the validator function will also be a list.\n",
    "\n",
    "We will pass the created class to the `PydanticOutputParser` wrapper to make it a `LangChain` parser object. The next step is to prepare the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitue the specified target_word based the presented context.\n",
    "{format_instructions}\n",
    "target_word={target_word}\n",
    "context={context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word=\"behaviour\"\n",
    "context=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template variable is a string incorporating named index placeholders in the following `{variable_name}` format. The template variable defines our prompts for the model, with the anticipated formatting from the output parser and the inputs (the `{format_instructions}` placeholder will be replaced by instructions from the output parser). The `PromptTemplate` takes in the template string, specifying the type of each placeholder. These placeholders can be categorized as `input_variables`, whose values are assigned later through the `.format_prompt()` method or `partial_variables`, defined immediately.\n",
    "\n",
    "For querying models like GPT, the prompt will be passed on LangChainâ€™s OpenAI wrapper. (Itâ€™s important to set the `OPENAI_API_KEY` environment variables with your API key from OpenAI.) Setting the temperature value to 0 also ensures that the outcomes are consistent and reproducible.\n",
    "\n",
    "> ðŸ’¡The temperature value could be between 0 and 1, where a higher number means the model is more creative. Using larger value in production is a good practice for tasks requiring creative output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=model, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LLMChain to get the AI-generated answer\n",
    "output = chain.run({\"target_word\": target_word, \"context\":context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parser objectâ€™s `parse()` function will convert the modelâ€™s string response to the format we specified. You can index through the list of words and use them in your applications. Notice the simplicity of accessing the third suggestion by calling the third index instead of dealing with a lengthy string that requires extensive preprocessing, as demonstrated in the initial example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example demonstrates a Pydantic class designed to handle multiple outputs. It instructs the model to generate a list of words and explain the reasoning behind each suggestion.\n",
    "\n",
    "To implement this example, replace the template variable and Suggestion class with the new code (provided below). The modifications in the prompt template force the model to elaborate on its reasoning. The updated Suggestion class introduces a new output named reasons. The validator function is also applied to modify the output, ensuring each explanation ends with a period. This example also illustrates how the validator function can be used for output manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "    reasons: List[str] = Field(description=\"the reasoning of why this word fits the context\")\n",
    "\n",
    "    # Throw error in case of recieving a numbered-list from API\n",
    "    @validator('words')\n",
    "    def not_start_with_number(cls, field):\n",
    "      for item in field:\n",
    "        if item[0].isnumeric():\n",
    "          raise ValueError(\"The word can not start with numbers!\")\n",
    "      return field\n",
    "\n",
    "    @validator('reasons')\n",
    "    def end_with_dot(cls, field):\n",
    "      for idx, item in enumerate( field ):\n",
    "        if item[-1] != \".\":\n",
    "          field[idx] += \".\"\n",
    "      return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitue the specified target_word based the presented context and the reasoning for each word.\n",
    "{format_instructions}\n",
    "target_word={target_word}\n",
    "context={context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=model, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LLMChain to get the AI-generated answer\n",
    "output = chain.run({\"target_word\": target_word, \"context\":context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class specializes in managing comma-separated outputs, focusing on instances where the model is expected to produce a list of outputs. To use this class efficiently, start by importing the necessary module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parser does not require any configuration. As a result, itâ€™s less adaptable and can only be used to process comma-separated strings. We can define the object by initializing the class. The steps for writing the prompt, initializing the model, and parsing the output are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitue the word '{target_word}' based the presented the following text: {context}.\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=model, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LLMChain to get the AI-generated answer\n",
    "output = chain.run({\"target_word\": target_word, \"context\":context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although most of the sample code has been explained in the previous subsection, two areas are new. First, we explored a new style for the prompt template. Second, the modelâ€™s input is generated using `.format()` rather than `.format_prompt()`. The key difference between this code and the one in the previous section is that we no longer need to call the `.to_string()` object because the prompt is already of string type.\n",
    "\n",
    "The final result is a list of words with some overlap with the `PydanticOutputParser` technique but with more variety. However, it is not possible to rely on the `CommaSeparatedOutputParser` **class** to elucidate the reasoning behind its output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StructuredOutputParser\n",
    "\n",
    "The `StructuredOutputParser` was one of the first parsers added to the LangChain library, and it remains widely used for handling structured outputs. It can manage more complex data types, including lists and **JSON-like** structures, rather than being limited to plain text. It is useful when you want a response from the model that adheres to a predefined schema, and it can support more than one response or multiple fields.\n",
    "\n",
    "For example, in a thesaurus application, you could define a schema where multiple substitute words are returned alongside their reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"words\", description=\"A substitute word based on context\"),\n",
    "    ResponseSchema(name=\"reasons\", description=\"\"\"the reasoning of why this word fits the context.\"\"\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `StructuredOutputParser` is commonly used in combination with libraries like Pydantic to validate and enforce the structure of data returned by the model. It offers significant flexibility for managing structured output, such as **JSON** objects, which makes it versatile for complex applications.\n",
    "\n",
    "While the `PydanticOutputParser` offers powerful validation capabilities for more intricate schemas, and the `CommaSeparatedOutputParser` can be suitable for simpler tasks, the `StructuredOutputParser` remains a flexible and robust option when more control over output formatting is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsers serve as robust tools for extracting information from prompts and providing a degree of validation. However, they cannot guarantee an accurate response for every use case. For example, in a scenario where an application is deployed, the modelâ€™s response to a user request is incomplete, leading the parser to generate an error. `OutputFixingParser` and `RetryOutputParser` function as **fail-safes**, adding a layer to the modelâ€™s response to rectify the mistakes.\n",
    "\n",
    "> ðŸ’¡The following approaches work with the PydanticOutputParser class since it is the only one with a validation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OutputFixingParser\n",
    "\n",
    "This method aims to fix parsing errors by examining the modelâ€™s response against the defined parser description using a large language model (LLM) to address the issue. For consistency with the rest of the book, GPT-3.5 will be used, but any compatible model will work. The first step defines the Pydantic data schema.\n",
    "\n",
    "Hereâ€™s a typical error that might arise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"\"\"list of substitue words based on context\"\"\")\n",
    "    reasons: List[str] = Field(description=\"\"\"the reasoning of why this word fits the context\"\"\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missformatted_output = '{\"words\": [\"conduct\", \"manner\"], \"reasoning\": [\"refers to the way someone acts in a particular situation.\", \"refers to the way someone behaves in a particular situation.\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(missformatted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message indicates that the parser successfully detected an error in our sample response (`missformatted_output`) due to the use of the word *reasoning* instead of the expected *reasons* key. The `OutputFixingParser` class is designed to correct such errors efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "outputfixing_parser = OutputFixingParser.from_llm(parser=parser, llm=model)\n",
    "outputfixing_parser.parse(missformatted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `from_llm()` function requires the previous parser and a language model as input parameters. It initializes a new parser equipped with the capability to rectify output errors. In this case, it identifies and modifies the incorrectly named key to match the defined requirement.\n",
    "\n",
    "However, itâ€™s important to note that resolving issues with the `OutputFixingParser` class may not always be feasible. The following example demonstrates using the `OutputFixingParser` class to address an error involving a missing key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missformatted_output = '{\"words\": [\"conduct\", \"manner\"]}'\n",
    "\n",
    "outputfixing_parser = OutputFixingParser.from_llm(parser=parser, llm=model)\n",
    "\n",
    "outputfixing_parser.parse(missformatted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the output, itâ€™s clear that the model recognized the absence of the reasons key in the response but lacked the context for fixing the response. Consequently, it generated a list with a single entry, whereas the expected output was one reason per word. This limitation underscores the occasional need for a more flexible approach like the `RetryOutputParser` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetryOutputParser\n",
    "\n",
    "There are situations where the parser requires access to both the output and the prompt to fully understand the context, as highlighted in the previous example. The first step is to define the required variables.\n",
    "\n",
    "The subsequent codes initiate the LLM, parser, and prompt described in earlier sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import RetryWithErrorOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "    reasons: List[str] = Field(description=\"the reasoning of why this word fits the context\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitue the specified target_word based the presented context and the reasoning for each word.\n",
    "{format_instructions}\n",
    "target_word={target_word}\n",
    "context={context}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model_input = prompt_template.format_prompt(target_word=\"behaviour\", context=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missformatted_output = '{\"words\": [\"conduct\", \"manner\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(missformatted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the same `missformatted_output` can be addressed using the `RetryWithErrorOutputParser` class. This class takes the defined parser and a model to create a new parser object. However, the `parse_with_prompt` function responsible for fixing the parsing issue requires both the generated output and the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_parser = RetryWithErrorOutputParser.from_llm(parser=parser, llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_parser.parse_with_prompt(missformatted_output, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results demonstrate that the `RetryOutputParser` successfully resolves the issue that the `OutputFixingParser` could not. The parser effectively guides the model to generate one reason for each word, as required.\n",
    "\n",
    "In a production environment, the recommended approach to integrating these techniques is to employ a **try...except...** method for error handling. This strategy captures parsing errors in the except block and attempts to fix them using the mentioned classes. This approach streamlines the process and limits the number of API calls, thereby reducing associated costs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-building-llm-powered-applications-with-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
